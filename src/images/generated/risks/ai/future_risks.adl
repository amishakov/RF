<?xml version="1.0" encoding="UTF-8"?>
<diagram
	xslt:template="/public/templates/risk-first/risk-first-template.xsl"
	xmlns="http://www.kite9.org/schema/adl"
	xmlns:xslt="http://www.kite9.org/schema/xslt" id="dia"
	style="--kite9-min-width: 900pt; --kite9-layout: down;">
	<group style="--kite9-layout: right; ">
		<group style="--kite9-layout: down; --kite9-vertical-align: top; ">
			<risk class="agency" id="id_0-wo" />
			<description  style="text-align: center; font-weight: bold; ">Loss of 
			human control</description>
			<description  style="text-align: center;  ">AI systems operating autonomously with minimal human oversight can lead to scenarios where we cannot override or re-align them with human values.</description>
		</group>
		<group style="--kite9-layout: down; --kite9-vertical-align: top; ">
			<risk class="security" id="id_2-wo" />
			<description  style="text-align: center;  font-weight: bold; ">Superintelligence with 
			malicious intent</description>
			<description  style="text-align: center;  ">An advanced AI could actively act against human interests, whether intentionally programmed that way or as an emergent behavior.</description>
		</group>
		<group style="--kite9-layout: down;  --kite9-vertical-align: top;">
			<risk class="complexity" id="id_2-wo" />
			<description  style="text-align: center;  font-weight: bold; ">Unintended 
			Cascading Failures</description>
			<description  style="text-align: center;  ">AI interacting with critical systems (finance, infrastructure, etc.) may trigger global-scale unintended consequences.</description>
		</group>
		<group style="--kite9-layout: down;  --kite9-vertical-align: top;">
			<risk class="feature-fit" id="id_3-wo" />
			<description  style="text-align: center; font-weight: bold;">Emergent, 
			Unhelpful Behaviour</description>
			<description  style="text-align: center;  ">AI develops unforeseen behaviors, capabilities, or self-replication that could lead to unpredictable consequences.</description>
		</group>
	</group>
	<group style="--kite9-layout: right; ">
		<group style="--kite9-layout: down;  --kite9-vertical-align: top;">
			<risk class="lock-in" id="id_2-wo" />
			<description  style="text-align: center;  font-weight: bold;">Loss of Diversity</description>
			<description  style="text-align: center;  ">A single AI system dominates globally, leading to catastrophic consequences if it fails, suppresses freedoms, or entrenches inequalities, consolidating power in few hands.</description>
		</group>
		<group style="--kite9-layout: down;  --kite9-vertical-align: top;">
			<risk class="coordination" id="id_4-wo" />
			<description  style="text-align: center; font-weight: bold; ">Synthetic Intelligence Rivalry</description>
			<description  style="text-align: center;  ">Rival AI entities could emerge with conflicting goals, leading to competition with humanity akin to geopolitical conflicts. (AI Colonialism)
</description>
		</group>
		<group style="--kite9-layout: down; --kite9-vertical-align: top; ">
			<risk class="communication" id="id_2-wo" />
			<description  style="text-align: center; font-weight: bold;">AI Social Manipulation</description>
			<description  style="text-align: center;  ">AI could predict and shape human behavior on an unprecedented scale.</description>
		</group>
	</group>
	
</diagram>
