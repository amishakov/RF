---
title: Transparency
description: Requiring AI developers to publish model architectures, data sources, generated data and decision-making rationales.
featured: 
  class: c
  element: '<action>Transparency</action>'
tags: 
  - Transparency
  - AI Practice
practice:
  mitigates:
   - tag: Loss Of Diversity
     reason: "Increases accountability but does not prevent monopolisation directly."
     efficacy: Medium
   - tag: Social Manipulation
     reason: "Require accountability and auditing mechanisms for social media platforms."
---

<PracticeIntro details={frontMatter} />

## Of Models, Data, Architecture

 - Requiring AI developers to publish model architectures, data sources, and decision-making rationales.

 - Transparency regulations are becoming more common but face resistance from corporate interests.

## Of Generated Content

 - Increases accountability but does not prevent monopolisation directly.

 - Mandate clear labeling of AI-generated content.

 - Require accountability and auditing mechanisms for social media platforms.
 
 – Requires infrastructure for labelling, auditing, and enforcement, but could be mandated by legislation.
 
 – Transparency can deter some manipulative actors, but determined bad actors may still evade or exploit labelling.

## Examples

  - [Generative AI and watermarking - European Parliament](https://www.europarl.europa.eu/RegData/etudes/BRIE/2023/757583/EPRS_BRI\(2023\)757583_EN.pdf)