---
title: Kill Switch
description:  Fail-safe systems capable of shutting down or isolating AI processes if they exhibit dangerous behaviours.
featured: 
  class: c
  element: '<action>Kill Switch Mechanism</action>'
tags: 
  - Kill Switch
  - AI Practice
practice:
  mitigates:
   - tag: Loss Of Human Control
     reason: "An explicit interruption capability can avert catastrophic errors or runaway behaviours"
   - tag: Synthetic Intelligence With Malicious Intent
     reason: Implementing fail-safe mechanisms to neutralise dangerous AI weapons systems.
---

<PracticeIntro details={frontMatter} />

## Examples
  
  - **Google DeepMind’s ‘Big Red Button’ concept** (2016), proposed as a method to interrupt a reinforcement learning AI without it learning to resist interruption.  
  
  - **Hardware Interrupts in Robotics:** Physical or software-based emergency stops that immediately terminate AI operation.  
