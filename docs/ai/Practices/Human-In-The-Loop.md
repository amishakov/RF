---
title: Human In The Loop
description:  Consistent human oversight in critical AI systems.
featured: 
  class: c
  element: '<action>Human In The Loop</action>'
tags: 
  - Human In The Loop
  - Practice
practice:
  mitigates:
   - tag: Loss Of Human Control
     reason: "Maintaining consistent human oversight in critical AI systems, ensuring that final decisions or interventions rest with human operators rather than the AI."
---

<PracticeIntro details={frontMatter} />

- Maintaining consistent human oversight in critical AI systems, ensuring that final decisions or interventions rest with human operators rather than the AI.  
- AI may suggest diagnoses or treatments, but a certified professional reviews and confirms before enacting them.  In the above NHS Grampian example, the AI is augmenting human decision making with a third opinion, rather than replacing human judgement altogether (yet).
- Some proposals mandate that human operators confirm critical actions (e.g., missile launches), preventing AI from unilaterally making life-or-death decisions.  This might work in scenarios where response time isn't a factor.

- **Efficacy:** Medium – Reduces risk by limiting autonomy on high-stakes tasks; however, humans may become complacent or fail to intervene effectively if over-trusting AI.  
- **Ease of Implementation:** Moderate – Policy, regulatory standards, and user training are needed to embed human oversight effectively.
